{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJDwuasZi9i2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_hourly = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/transformers_dataset.csv\"\n",
        "df_hourly = pd.read_csv(url_hourly,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
        "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# df_count = df_daily.groupby('id').count()\n",
        "\n",
        "# df_count = df_count.sort_values('datahora').tail(41).reset_index() # esses são os trafos com mais de 97,5% de linhas preenchidas\n",
        "# trafos_escolhidos = df_count['id'].unique().tolist()\n",
        "# df_filtrado = df_daily[df_daily['id'].isin(trafos_escolhidos)]\n",
        "\n",
        "# fig_aparente = px.line(df_filtrado, x='datahora', y='S', color='id',\n",
        "#                        title='Potência Aparente ao Longo do Tempo por Transformador',\n",
        "#                        labels={'S': 'Potência Aparente (kVA)', 'Dia': 'Data'})\n",
        "\n",
        "# fig_aparente.show()\n",
        "# fig_aparente.write_html(\"Demanda ao longo do tempo - IQR.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8xHrY-i9jH"
      },
      "source": [
        "#### Algoritmo de Aprendizado de Máquina - Pico Diário, 1 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gw3U9O2vi9jK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Treinando SVR para T1 (daily)...\n",
            "✅ Modelo salvo em: modelos/SVR_T1.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.05 0.03\n",
            "1  Fold 2    T1    SVR  0.04 0.03\n",
            "2  Fold 3    T1    SVR  0.04 0.03\n",
            "3  Fold 4    T1    SVR  0.05 0.03\n",
            "4  Fold 5    T1    SVR  0.05 0.04\n",
            "\n",
            "🔹 Treinando SVR para T1 (hourly)...\n",
            "✅ Modelo salvo em: modelos/SVR_T1.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.07 0.05\n",
            "1  Fold 2    T1    SVR  0.07 0.05\n",
            "2  Fold 3    T1    SVR  0.06 0.04\n",
            "3  Fold 4    T1    SVR  0.06 0.04\n",
            "4  Fold 5    T1    SVR  0.06 0.05\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# IMPORTAÇÕES E CONFIGURAÇÕES\n",
        "# ========================================================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "import keras_tuner as kt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Fixando seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ========================================================================\n",
        "def gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae):\n",
        "    return pd.DataFrame({\n",
        "        'Fold': [f'Fold {i+1}' for i in range(len(fold_rmse))],\n",
        "        'Trafo': trafo,\n",
        "        'Modelo': modelo,\n",
        "        'RMSE': np.round(fold_rmse, 4),\n",
        "        'MAE': np.round(fold_mae, 4)\n",
        "    })\n",
        "\n",
        "def plotar_ultimo_fold(datas, y_real, y_pred, trafo, modelo, freq):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(datas, y_real, label='Real', color='blue')\n",
        "    plt.plot(datas, y_pred, label=f'Previsto ({modelo})', linestyle='--', color='orange')\n",
        "    plt.xlabel('Dia' if freq=='daily' else 'Hora')\n",
        "    plt.ylabel('Potência Aparente (kVA)')\n",
        "    plt.title(f'Previsão Último Fold - {modelo} ({trafo})')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    os.makedirs('plots', exist_ok=True)\n",
        "    plt.savefig(f'plots/PLOT_{modelo}_{trafo}_{freq}_ultimo_fold.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label='Data'):\n",
        "    datas_todas = pd.to_datetime(np.concatenate(lista_datas))\n",
        "    reais_todos = np.concatenate(lista_reais)\n",
        "    previstos_todos = np.concatenate(lista_previstos)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=reais_todos, mode='lines', name='Real', line=dict(color='blue')))\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=previstos_todos, mode='lines', name=f'Previsto ({modelo})', line=dict(color='orange', dash='dash')))\n",
        "    fig.update_layout(title=f'Previsão em Todos os Folds - {trafo} ({modelo})',\n",
        "                      xaxis_title=eixo_label, yaxis_title='Potência Aparente', hovermode='x unified')\n",
        "    fig.show()\n",
        "\n",
        "# ========================================================================\n",
        "# HYPERPARAMS PARA RANDOMIZEDSEARCH\n",
        "# ========================================================================\n",
        "param_grids = {\n",
        "    'SVR': {\n",
        "        'C': [0.1, 1, 10, 100, 1000],\n",
        "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
        "        'epsilon': [0.001, 0.01, 0.1, 0.5]\n",
        "    },\n",
        "    'RFR': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'GBR': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    },\n",
        "    'XGB': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3,5,7]\n",
        "    },\n",
        "    'LGBM': {\n",
        "        'n_estimators': [50,100,200],\n",
        "        'learning_rate': [0.01,0.05,0.1],\n",
        "        'max_depth': [-1,3,5,7]\n",
        "    }\n",
        "}\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÃO PRINCIPAL\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_auto(data, trafos_escolhidos, modelo, janela=None, epochs=20, batch_size=32, n_iter_search=10):\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "    data['datahora'] = pd.to_datetime(data['datahora'])\n",
        "    \n",
        "    delta = data['datahora'].diff().median()\n",
        "    if delta >= pd.Timedelta('1D'):\n",
        "        freq = 'daily'\n",
        "        if janela is None: janela = 30\n",
        "        eixo_label = 'Dia'\n",
        "    else:\n",
        "        freq = 'hourly'\n",
        "        if janela is None: janela = 24*7\n",
        "        eixo_label = 'Hora'\n",
        "        # Filtra só 2023 e 2024\n",
        "        data = data[(data['datahora'].dt.year >= 2023) & (data['datahora'].dt.year <= 2024)]\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\n🔹 Treinando {modelo} para {trafo} ({freq})...\")\n",
        "        df = data[data['id']==trafo].copy()\n",
        "        df = df[['datahora','S']].sort_values('datahora').dropna()\n",
        "        \n",
        "        # Janelas deslizantes\n",
        "        X, y, datas_janela = [], [], []\n",
        "        S_values = df['S'].values\n",
        "        datas = df['datahora'].values\n",
        "        for i in range(janela, len(df)):\n",
        "            X.append(S_values[i-janela:i])\n",
        "            y.append(S_values[i])\n",
        "            datas_janela.append(datas[i])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        datas_janela = np.array(datas_janela)\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']: X = X.reshape((X.shape[0], X.shape[1],1))\n",
        "        else: X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ====================\n",
        "            # MODELOS COM HYPERPARAMS\n",
        "            # ====================\n",
        "            if modelo in param_grids.keys(): # scikit-learn\n",
        "                base_model = {\n",
        "                    'SVR': SVR(),\n",
        "                    'RFR': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "                    'GBR': GradientBoostingRegressor(random_state=42),\n",
        "                    'XGB': XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
        "                    'LGBM': LGBMRegressor(random_state=42)\n",
        "                }[modelo]\n",
        "                search = RandomizedSearchCV(base_model, param_distributions=param_grids[modelo],\n",
        "                                            n_iter=n_iter_search, scoring='neg_mean_squared_error',\n",
        "                                            cv=TimeSeriesSplit(n_splits=3), n_jobs=-1, random_state=42)\n",
        "                search.fit(X_train, y_train)\n",
        "                best_model = search.best_estimator_\n",
        "                y_pred = best_model.predict(X_test)\n",
        "\n",
        "            else: # Redes neurais\n",
        "                def build_nn(hp):\n",
        "                    model = Sequential()\n",
        "                    if modelo=='LSTM':\n",
        "                        model.add(LSTM(units=hp.Int('units1', 20, 100, step=20), return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(LSTM(units=hp.Int('units2',20,100, step=20)))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    elif modelo=='CNN':\n",
        "                        model.add(Conv1D(filters=hp.Int('filters',32,128,step=32), kernel_size=2, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(Flatten())\n",
        "                        model.add(Dense(hp.Int('dense',10,50,step=10), activation='relu'))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    elif modelo=='CNN_LSTM':\n",
        "                        model.add(Conv1D(filters=hp.Int('filters',32,128,step=32), kernel_size=2, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(LSTM(units=hp.Int('units1',20,100,step=20), return_sequences=True))\n",
        "                        model.add(LSTM(units=hp.Int('units2',20,100,step=20)))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    return model\n",
        "                tuner = kt.RandomSearch(build_nn, objective='val_loss', max_trials=5, overwrite=True)\n",
        "                tuner.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
        "                best_model = tuner.get_best_models(num_models=1)[0]\n",
        "                y_pred = best_model.predict(X_test).flatten()\n",
        "\n",
        "            # ====================\n",
        "            # MÉTRICAS\n",
        "            # ====================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "\n",
        "        # Plot do último fold\n",
        "        plotar_ultimo_fold(lista_datas[-1], lista_reais[-1], lista_previstos[-1], trafo, modelo, freq)\n",
        "\n",
        "        # Salva modelo final\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}.{'h5' if modelo in ['LSTM','CNN','CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']:\n",
        "            best_model.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(best_model, modelo_path)\n",
        "        print(f\"✅ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # Métricas\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        # Plot todos folds\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label=eixo_label)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE Médio': np.round(np.mean(fold_rmse),4),\n",
        "            'MAE Médio': np.round(np.mean(fold_mae),4),\n",
        "            'RMSE Último Fold': np.round(fold_rmse[-1],4),\n",
        "            'MAE Último Fold': np.round(fold_mae[-1],4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# ========================================================================\n",
        "# USO\n",
        "# ========================================================================\n",
        "trafos = ['T1']\n",
        "resultados_SVR_daily = treinar_e_prever_modelo_auto(df_daily, trafos, modelo='SVR', janela=30, n_iter_search=10)\n",
        "resultados_SVR_hourly = treinar_e_prever_modelo_auto(df_hourly, trafos, modelo='SVR', janela=168, n_iter_search=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Lista de transformadores e modelos\n",
        "trafos = ['T1', 'T2']\n",
        "modelos = ['SVR', 'XGB', 'LGBM', 'GBR', 'LSTM', 'CNN', 'CNN_LSTM']\n",
        "\n",
        "# Diretório base onde estão os modelos\n",
        "base_dir = r\"G:\\Meu Drive\\Estudos\\Mestrado\\Github\\masters\\modelos\"\n",
        "\n",
        "# Dicionário para armazenar os modelos carregados\n",
        "modelos_carregados = {}\n",
        "\n",
        "for trafo in trafos:\n",
        "    for modelo in modelos:\n",
        "        # Define a extensão correta\n",
        "        extensao = \"h5\" if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"] else \"pkl\"\n",
        "        caminho = os.path.join(base_dir, f\"{modelo}_{trafo}.{extensao}\")\n",
        "        \n",
        "        # Inicializa a chave no dicionário\n",
        "        modelos_carregados[(modelo, trafo)] = None\n",
        "        \n",
        "        # Carrega apenas se o arquivo existir\n",
        "        if os.path.exists(caminho):\n",
        "            if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"]:\n",
        "                modelos_carregados[(modelo, trafo)] = load_model(caminho)\n",
        "            else:\n",
        "                modelos_carregados[(modelo, trafo)] = joblib.load(caminho)\n",
        "            print(f\"✅ Modelo carregado: {caminho}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Arquivo não encontrado, ignorando: {caminho}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos analisar seus dados originais para entender a estrutura\n",
        "print(\"=== ANALISANDO DADOS ORIGINAIS ===\")\n",
        "print(f\"Shape do df_daily: {df_daily.shape}\")\n",
        "print(f\"Colunas: {df_daily.columns.tolist()}\")\n",
        "print(f\"Tipos de dados:\\n{df_daily.dtypes}\")\n",
        "\n",
        "# Ver um exemplo dos dados do T1\n",
        "print(\"\\n=== DADOS DO TRAFO T1 ===\")\n",
        "df_t1 = df_daily[df_daily['id'] == 'T1'].copy()\n",
        "print(f\"Quantidade de dados T1: {len(df_t1)}\")\n",
        "print(f\"Período: {df_t1['datahora'].min()} até {df_t1['datahora'].max()}\")\n",
        "print(f\"Primeiras linhas T1:\")\n",
        "print(df_t1.head())\n",
        "\n",
        "# Ver a distribuição da variável target 'S'\n",
        "print(f\"\\nEstatísticas da Potência Aparente (S):\")\n",
        "print(df_t1['S'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TREINNAMENTO ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_hourly = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/transformers_dataset.csv\"\n",
        "df_hourly = pd.read_csv(url_hourly,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
        "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Iniciando treinamento com configurações otimizadas...\n",
            "\n",
            "📊 Treinando com dados DIÁRIOS (configuração padrão)...\n",
            "\n",
            "🔹 Treinando SVR para T1 (daily)...\n",
            "   Fold 1: RMSE=0.0473, MAE=0.0313\n",
            "   Fold 2: RMSE=0.0413, MAE=0.0294\n",
            "   Fold 3: RMSE=0.0362, MAE=0.0268\n",
            "   Fold 4: RMSE=0.0477, MAE=0.0326\n",
            "   Fold 5: RMSE=0.0527, MAE=0.0398\n",
            "✅ Modelo salvo em: modelos/SVR_T1_daily.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.05 0.03\n",
            "1  Fold 2    T1    SVR  0.04 0.03\n",
            "2  Fold 3    T1    SVR  0.04 0.03\n",
            "3  Fold 4    T1    SVR  0.05 0.03\n",
            "4  Fold 5    T1    SVR  0.05 0.04\n",
            "\n",
            "✅ Todos os treinamentos concluídos!\n",
            "\n",
            "Resultados Horários:\n",
            "  Trafo Modelo  RMSE Médio  MAE Médio  RMSE Último Fold  MAE Último Fold\n",
            "0    T1    SVR        0.06       0.05              0.06             0.05\n",
            "\n",
            "Resultados Diários:\n",
            "  Trafo Modelo Frequência  RMSE Médio  MAE Médio  RMSE Último Fold  \\\n",
            "0    T1    SVR      daily        0.04       0.03              0.05   \n",
            "\n",
            "   MAE Último Fold  \n",
            "0             0.04  \n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# IMPORTAÇÕES E CONFIGURAÇÕES\n",
        "# ========================================================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Fixando seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ========================================================================\n",
        "def gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae):\n",
        "    return pd.DataFrame({\n",
        "        'Fold': [f'Fold {i+1}' for i in range(len(fold_rmse))],\n",
        "        'Trafo': trafo,\n",
        "        'Modelo': modelo,\n",
        "        'RMSE': np.round(fold_rmse, 4),\n",
        "        'MAE': np.round(fold_mae, 4)\n",
        "    })\n",
        "\n",
        "def plotar_ultimo_fold(datas, y_real, y_pred, trafo, modelo, freq):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(datas, y_real, label='Real', color='blue')\n",
        "    plt.plot(datas, y_pred, label=f'Previsto ({modelo})', linestyle='--', color='orange')\n",
        "    plt.xlabel('Dia' if freq=='daily' else 'Hora')\n",
        "    plt.ylabel('Potência Aparente (kVA)')\n",
        "    plt.title(f'Previsão Último Fold - {modelo} ({trafo})')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    os.makedirs('plots', exist_ok=True)\n",
        "    plt.savefig(f'plots/PLOT_{modelo}_{trafo}_{freq}_ultimo_fold.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label='Data'):\n",
        "    datas_todas = pd.to_datetime(np.concatenate(lista_datas))\n",
        "    reais_todos = np.concatenate(lista_reais)\n",
        "    previstos_todos = np.concatenate(lista_previstos)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=reais_todos, mode='lines', name='Real', line=dict(color='blue')))\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=previstos_todos, mode='lines', name=f'Previsto ({modelo})', line=dict(color='orange', dash='dash')))\n",
        "    fig.update_layout(title=f'Previsão em Todos os Folds - {trafo} ({modelo})',\n",
        "                      xaxis_title=eixo_label, yaxis_title='Potência Aparente', hovermode='x unified')\n",
        "    fig.show()\n",
        "\n",
        "# ========================================================================\n",
        "# HYPERPARAMS OTIMIZADOS\n",
        "# ========================================================================\n",
        "param_grids_base = {\n",
        "    'SVR': {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': ['scale', 'auto', 0.01, 0.1],\n",
        "        'epsilon': [0.01, 0.1, 0.5]\n",
        "    },\n",
        "    'RFR': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [5, 10, 15],\n",
        "        'min_samples_split': [2, 5]\n",
        "    },\n",
        "    'GBR': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    },\n",
        "    'XGB': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    },\n",
        "    'LGBM': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_param_grids_por_freq(freq, modelo):\n",
        "    \"\"\"Retorna grid de parâmetros baseado na frequência dos dados\"\"\"\n",
        "    base_params = param_grids_base[modelo].copy()\n",
        "    \n",
        "    if freq == 'hourly':  # Dados horários - grids mais simples\n",
        "        if modelo == 'SVR':\n",
        "            base_params['C'] = [1, 10]\n",
        "            base_params['gamma'] = ['scale', 0.01]\n",
        "            base_params['epsilon'] = [0.1]\n",
        "        elif modelo in ['RFR', 'GBR', 'XGB', 'LGBM']:\n",
        "            base_params['n_estimators'] = [50, 100]  # Menos árvores\n",
        "    return base_params\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÃO PRINCIPAL OTIMIZADA\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_auto_otimizado(data, trafos_escolhidos, modelo, janela=None, epochs=15, batch_size=32, n_iter_search=5):\n",
        "    \"\"\"Versão otimizada da função principal\"\"\"\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "    data['datahora'] = pd.to_datetime(data['datahora'])\n",
        "    \n",
        "    # Determina frequência e configurações\n",
        "    delta = data['datahora'].diff().median()\n",
        "    if delta >= pd.Timedelta('1D'):\n",
        "        freq = 'daily'\n",
        "        if janela is None: janela = 30\n",
        "        eixo_label = 'Dia'\n",
        "    else:\n",
        "        freq = 'hourly'\n",
        "        if janela is None: janela = 24*3  # 3 dias em vez de 7\n",
        "        eixo_label = 'Hora'\n",
        "        # Filtra só 2023 e 2024 de forma mais eficiente\n",
        "        data = data[data['datahora'].dt.year.isin([2023, 2024])].copy()\n",
        "\n",
        "    # PRÉ-COMPUTAÇÃO: Criar dicionário com dados de cada trafo\n",
        "    dados_trafos = {}\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df_trafo = data[data['id']==trafo][['datahora','S']].sort_values('datahora').dropna()\n",
        "        dados_trafos[trafo] = {\n",
        "            'S_values': df_trafo['S'].values,\n",
        "            'datas': df_trafo['datahora'].values\n",
        "        }\n",
        "\n",
        "    # Configurações específicas por frequência\n",
        "    if freq == 'hourly':\n",
        "        n_iter_search = max(2, n_iter_search // 2)  # Menos iterações\n",
        "        epochs = min(10, epochs)  # Menos epochs\n",
        "        batch_size = min(64, batch_size)  # Batch menor\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\n🔹 Treinando {modelo} para {trafo} ({freq})...\")\n",
        "        \n",
        "        # Uso dos dados pré-computados\n",
        "        S_values = dados_trafos[trafo]['S_values']\n",
        "        datas = dados_trafos[trafo]['datas']\n",
        "        \n",
        "        # Criação MAIS EFICIENTE das janelas usando sliding_window_view\n",
        "        n_samples = len(S_values) - janela\n",
        "        if n_samples <= 0:\n",
        "            print(f\"⚠️ Dados insuficientes para {trafo}. Pulando...\")\n",
        "            continue\n",
        "            \n",
        "        X = np.lib.stride_tricks.sliding_window_view(S_values, janela)[:n_samples]\n",
        "        y = S_values[janela:janela + n_samples]\n",
        "        datas_janela = datas[janela:janela + n_samples]\n",
        "        \n",
        "        # Reshape para modelos\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']: \n",
        "            X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "        else: \n",
        "            X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ====================\n",
        "            # MODELOS COM HYPERPARAMS OTIMIZADOS\n",
        "            # ====================\n",
        "            if modelo in param_grids_base.keys(): # scikit-learn\n",
        "                param_grid_freq = get_param_grids_por_freq(freq, modelo)\n",
        "                \n",
        "                base_model = {\n",
        "                    'SVR': SVR(),\n",
        "                    'RFR': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "                    'GBR': GradientBoostingRegressor(random_state=42),\n",
        "                    'XGB': XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
        "                    'LGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)  # Silencioso\n",
        "                }[modelo]\n",
        "                \n",
        "                # RandomizedSearch mais rápido\n",
        "                search = RandomizedSearchCV(\n",
        "                    base_model, \n",
        "                    param_distributions=param_grid_freq,\n",
        "                    n_iter=n_iter_search, \n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=TimeSeriesSplit(n_splits=2),  # Menos folds de validação\n",
        "                    n_jobs=1 if modelo in ['SVR'] else -1,  # SVR não paraleliza bem\n",
        "                    random_state=42,\n",
        "                    verbose=0  # Silencioso\n",
        "                )\n",
        "                search.fit(X_train, y_train)\n",
        "                best_model = search.best_estimator_\n",
        "                y_pred = best_model.predict(X_test)\n",
        "\n",
        "            else: # Redes neurais\n",
        "                def build_nn_otimizada(hp):\n",
        "                    model = Sequential()\n",
        "                    \n",
        "                    # Configurações baseadas na frequência\n",
        "                    units_multiplier = 0.7 if freq == 'hourly' else 1\n",
        "                    \n",
        "                    if modelo == 'LSTM':\n",
        "                        model.add(LSTM(\n",
        "                            units=hp.Int('units1', \n",
        "                                       int(20*units_multiplier), \n",
        "                                       int(80*units_multiplier), \n",
        "                                       step=20), \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(Dense(1))\n",
        "                    elif modelo == 'CNN':\n",
        "                        model.add(Conv1D(\n",
        "                            filters=hp.Int('filters', 32, 64, step=32), \n",
        "                            kernel_size=2, \n",
        "                            activation='relu', \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(Flatten())\n",
        "                        model.add(Dense(1))\n",
        "                    elif modelo == 'CNN_LSTM':\n",
        "                        model.add(Conv1D(\n",
        "                            filters=32, \n",
        "                            kernel_size=2, \n",
        "                            activation='relu', \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(LSTM(\n",
        "                            units=hp.Int('units1', 20, 60, step=20)\n",
        "                        ))\n",
        "                        model.add(Dense(1))\n",
        "                    \n",
        "                    model.compile(optimizer='adam', loss='mse')\n",
        "                    return model\n",
        "                \n",
        "                # Early stopping para redes neurais\n",
        "                early_stop = EarlyStopping(\n",
        "                    monitor='val_loss', \n",
        "                    patience=3, \n",
        "                    restore_best_weights=True\n",
        "                )\n",
        "                \n",
        "                tuner = kt.RandomSearch(\n",
        "                    build_nn_otimizada,\n",
        "                    objective='val_loss',\n",
        "                    max_trials=3,  # Menos trials\n",
        "                    overwrite=True,\n",
        "                    executions_per_trial=1,\n",
        "                    directory='keras_tuner',\n",
        "                    project_name=f'{modelo}_{trafo}_{freq}'\n",
        "                )\n",
        "                \n",
        "                tuner.search(\n",
        "                    X_train, y_train, \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stop],\n",
        "                    verbose=0\n",
        "                )\n",
        "                \n",
        "                best_model = tuner.get_best_models(num_models=1)[0]\n",
        "                y_pred = best_model.predict(X_test).flatten()\n",
        "\n",
        "            # ====================\n",
        "            # MÉTRICAS\n",
        "            # ====================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "            \n",
        "            print(f\"   Fold {fold_idx+1}: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "        # Plot do último fold\n",
        "        plotar_ultimo_fold(lista_datas[-1], lista_reais[-1], lista_previstos[-1], trafo, modelo, freq)\n",
        "\n",
        "        # Salva modelo final\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}_{freq}.{'h5' if modelo in ['LSTM','CNN','CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']:\n",
        "            best_model.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(best_model, modelo_path)\n",
        "        print(f\"✅ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # Métricas\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        # Plot todos folds\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label=eixo_label)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'Frequência': freq,\n",
        "            'RMSE Médio': np.round(np.mean(fold_rmse),4),\n",
        "            'MAE Médio': np.round(np.mean(fold_mae),4),\n",
        "            'RMSE Último Fold': np.round(fold_rmse[-1],4),\n",
        "            'MAE Último Fold': np.round(fold_mae[-1],4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# ========================================================================\n",
        "# USO OTIMIZADO\n",
        "# ========================================================================\n",
        "trafos = ['T1']\n",
        "\n",
        "print(\"🚀 Iniciando treinamento com configurações otimizadas...\")\n",
        "\n",
        "# Para dados diários - configurações normais\n",
        "print(\"\\n📊 Treinando com dados DIÁRIOS (configuração padrão)...\")\n",
        "\n",
        "resultados_SVR_daily = treinar_e_prever_modelo_auto_otimizado(\n",
        "    df_daily, \n",
        "    trafos, \n",
        "    'SVR', \n",
        "    janela=30,\n",
        "    n_iter_search=5,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Todos os treinamentos concluídos!\")\n",
        "print(\"\\nResultados Horários:\")\n",
        "print(resultados_SVR_hourly)\n",
        "print(\"\\nResultados Diários:\")\n",
        "print(resultados_SVR_daily)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Treinando LGBM para T1 (hourly)...\n",
            "   Fold 1: RMSE=0.0509, MAE=0.0358\n",
            "   Fold 2: RMSE=0.0609, MAE=0.0439\n",
            "   Fold 3: RMSE=0.0505, MAE=0.0352\n",
            "   Fold 4: RMSE=0.0495, MAE=0.0332\n",
            "   Fold 5: RMSE=0.0576, MAE=0.0392\n",
            "✅ Modelo salvo em: modelos/LGBM_T1_hourly.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1   LGBM  0.05 0.04\n",
            "1  Fold 2    T1   LGBM  0.06 0.04\n",
            "2  Fold 3    T1   LGBM  0.05 0.04\n",
            "3  Fold 4    T1   LGBM  0.05 0.03\n",
            "4  Fold 5    T1   LGBM  0.06 0.04\n"
          ]
        }
      ],
      "source": [
        "# Teste rápido com dados horários\n",
        "resultados = treinar_e_prever_modelo_auto_otimizado(\n",
        "    df_hourly, \n",
        "    ['T1'], \n",
        "    'LGBM',  # Mais rápido que SVR\n",
        "    janela=24*3, \n",
        "    n_iter_search=2,\n",
        "    epochs=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CRIANDO FEATURES SAZONAIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diário, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_daily(df_daily):\n",
        "    df_featured_daily = df_daily.copy()\n",
        "        \n",
        "    # Features para dados diários\n",
        "    df_featured_daily['datahora'] = pd.to_datetime(df_featured_daily['datahora'])\n",
        "    df_featured_daily = df_featured_daily.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_daily['day_of_week'] = df_featured_daily['datahora'].dt.dayofweek\n",
        "    df_featured_daily['month'] = df_featured_daily['datahora'].dt.month\n",
        "    df_featured_daily['year'] = df_featured_daily['datahora'].dt.year\n",
        "    df_featured_daily['is_weekend'] = (df_featured_daily['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features cíclicas diárias\n",
        "    df_featured_daily['sin_day_of_week'] = np.sin(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['cos_day_of_week'] = np.cos(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['sin_month'] = np.sin(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    df_featured_daily['cos_month'] = np.cos(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    \n",
        "    # Lags diários (sazonais)\n",
        "    for lag in [1, 7, 30, 365]:  # 1 dia, 1 semana, 1 mês, 1 ano\n",
        "        df_featured_daily[f'S{lag}'] = df_featured_daily.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # Médias móveis diárias\n",
        "    for window in [7, 30, 90]:  # 1 semana, 1 mês, 3 meses\n",
        "        df_featured_daily[f'S_rolling_mean_{window}'] = df_featured_daily.groupby('id')['S'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).mean())\n",
        "        \n",
        "    return df_featured_daily\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados diários...\")\n",
        "daily_features = criar_features_daily(df_daily)\n",
        "daily_features\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"✅ Features diárias criadas com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hora em Hora, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_hourly(df_hourly):\n",
        "    # \"\"\"Cria features específicas para cada modo\"\"\"    \n",
        "    df_featured_hourly = df_hourly.copy()\n",
        "\n",
        "    # Features para dados horários\n",
        "    df_featured_hourly['datahora'] = pd.to_datetime(df_featured_hourly['datahora'])\n",
        "    df_featured_hourly = df_featured_hourly.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_hourly['hour'] = df_featured_hourly['datahora'].dt.hour\n",
        "    df_featured_hourly['day_of_week'] = df_featured_hourly['datahora'].dt.dayofweek\n",
        "    df_featured_hourly['is_weekend'] = (df_featured_hourly['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features cíclicas horárias\n",
        "    df_featured_hourly['sin_hour'] = np.sin(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    df_featured_hourly['cos_hour'] = np.cos(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    \n",
        "    # Lags horários\n",
        "    for lag in [1, 24, 168]:  # 1h, 1 dia, 1 semana\n",
        "        df_featured_hourly[f'S_lag_{lag}'] = df_featured_hourly.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # Médias móveis horárias\n",
        "    df_featured_hourly['S_rolling_mean_24'] = df_featured_hourly.groupby('id')['S'].transform(\n",
        "        lambda x: x.rolling(24, min_periods=1).mean())\n",
        "        \n",
        "        \n",
        "    return df_featured_hourly\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados horários...\")\n",
        "hourly_features = criar_features_hourly(df_hourly)\n",
        "\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"✅ Features horárias criadas com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TREINANDO MULTI-FEATURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÃO PRINCIPAL DE TREINAMENTO E PREVISÃO (ATUALIZADA)\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_ft(data, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    \"\"\"\n",
        "    Função para treinar e prever modelos de séries temporais com múltiplas features.\n",
        "    \n",
        "    Parâmetros:\n",
        "        data (DataFrame): dataframe com colunas ['id', 'datahora', 'S'] + features extras\n",
        "        trafos_escolhidos (list): lista de transformadores a treinar\n",
        "        modelo (str): nome do modelo ('SVR', 'RFR', 'GBR', 'XGB', 'LGBM', 'LSTM', 'CNN', 'CNN_LSTM')\n",
        "        janela (int): tamanho da janela deslizante (número de passos anteriores)\n",
        "        epochs (int): número de épocas (para redes neurais)\n",
        "        batch_size (int): tamanho do batch (para redes neurais)\n",
        "    \n",
        "    Retorna:\n",
        "        DataFrame com as métricas médias por trafo.\n",
        "    \"\"\"\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\n🔹 Treinando {modelo} para {trafo}...\")\n",
        "\n",
        "        # ======================\n",
        "        # 1. Preparação dos dados\n",
        "        # ======================\n",
        "        df = data[data['id'] == trafo].copy()\n",
        "        df = df.sort_values('datahora').dropna().reset_index(drop=True)\n",
        "\n",
        "        # Seleciona todas as colunas numéricas exceto 'id', 'datahora' e 'S'\n",
        "        feature_cols = [c for c in df.columns if c not in ['id', 'datahora', 'S']]\n",
        "        target_col = 'S'\n",
        "\n",
        "        X_raw = df[feature_cols].values\n",
        "        y_raw = df[target_col].values\n",
        "        datas = df['datahora'].values\n",
        "\n",
        "        # Cria janelas deslizantes\n",
        "        X, y, datas_janela = [], [], []\n",
        "        for i in range(janela, len(df)):\n",
        "            X.append(X_raw[i-janela:i])   # entrada: janela com features\n",
        "            y.append(y_raw[i])            # saída: valor atual\n",
        "            datas_janela.append(datas[i]) # datas para plot\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        datas_janela = np.array(datas_janela)\n",
        "\n",
        "        # Ajuste de shape\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))  # (amostras, timesteps, features)\n",
        "        else:\n",
        "            X = X.reshape(X.shape[0], -1)  # achata janelas + features\n",
        "\n",
        "        # ======================\n",
        "        # 2. Cross-validation temporal\n",
        "        # ======================\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ======================\n",
        "            # 3. Inicializa modelo\n",
        "            # ======================\n",
        "            if modelo == 'SVR':\n",
        "                regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "            elif modelo == 'RFR':\n",
        "                regressor = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
        "            elif modelo == 'GBR':\n",
        "                regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'LGBM':\n",
        "                regressor = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'XGB':\n",
        "                regressor = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
        "            elif modelo == 'LSTM':\n",
        "                regressor = Sequential([\n",
        "                    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    Flatten(),\n",
        "                    Dense(50, activation='relu'),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN_LSTM':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    LSTM(50, return_sequences=True),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "            # ======================\n",
        "            # 4. Treinamento\n",
        "            # ======================\n",
        "            if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "                regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "                y_pred = regressor.predict(X_test)\n",
        "            else:\n",
        "                regressor.fit(X_train, y_train)\n",
        "                y_pred = regressor.predict(X_test)\n",
        "\n",
        "            # ======================\n",
        "            # 5. Avaliação\n",
        "            # ======================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "\n",
        "            if fold_idx == 4:\n",
        "                plotar_resultados(datas_finais, y_test, y_pred, trafo, modelo)\n",
        "\n",
        "        # ======================\n",
        "        # 6. Salva modelo final\n",
        "        # ======================\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}.{'h5' if modelo in ['LSTM', 'CNN', 'CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            regressor.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(regressor, modelo_path)\n",
        "        print(f\"✅ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # ======================\n",
        "        # 7. Métricas e plots\n",
        "        # ======================\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE Médio': np.round(np.mean(fold_rmse), 4),\n",
        "            'MAE Médio': np.round(np.mean(fold_mae), 4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trafos = ['T1']\n",
        "\n",
        "# resultados_XGB = treinar_e_prever_modelo(df_daily, trafos, modelo='XGB', janela=365)\n",
        "resultados_XGB_ft = treinar_e_prever_modelo_ft(daily_features, trafos, modelo='XGB', janela=365)\n",
        "# resultados_LGBM = treinar_e_prever_modelo(daily_features, trafos, modelo='LGBM', janela=365)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
