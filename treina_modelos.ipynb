{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJDwuasZi9i2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_hourly = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/transformers_dataset.csv\"\n",
        "df_hourly = pd.read_csv(url_hourly,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
        "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# df_count = df_daily.groupby('id').count()\n",
        "\n",
        "# df_count = df_count.sort_values('datahora').tail(41).reset_index() # esses s√£o os trafos com mais de 97,5% de linhas preenchidas\n",
        "# trafos_escolhidos = df_count['id'].unique().tolist()\n",
        "# df_filtrado = df_daily[df_daily['id'].isin(trafos_escolhidos)]\n",
        "\n",
        "# fig_aparente = px.line(df_filtrado, x='datahora', y='S', color='id',\n",
        "#                        title='Pot√™ncia Aparente ao Longo do Tempo por Transformador',\n",
        "#                        labels={'S': 'Pot√™ncia Aparente (kVA)', 'Dia': 'Data'})\n",
        "\n",
        "# fig_aparente.show()\n",
        "# fig_aparente.write_html(\"Demanda ao longo do tempo - IQR.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8xHrY-i9jH"
      },
      "source": [
        "#### Algoritmo de Aprendizado de M√°quina - Pico Di√°rio, 1 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gw3U9O2vi9jK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîπ Treinando SVR para T1 (daily)...\n",
            "‚úÖ Modelo salvo em: modelos/SVR_T1.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.05 0.03\n",
            "1  Fold 2    T1    SVR  0.04 0.03\n",
            "2  Fold 3    T1    SVR  0.04 0.03\n",
            "3  Fold 4    T1    SVR  0.05 0.03\n",
            "4  Fold 5    T1    SVR  0.05 0.04\n",
            "\n",
            "üîπ Treinando SVR para T1 (hourly)...\n",
            "‚úÖ Modelo salvo em: modelos/SVR_T1.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.07 0.05\n",
            "1  Fold 2    T1    SVR  0.07 0.05\n",
            "2  Fold 3    T1    SVR  0.06 0.04\n",
            "3  Fold 4    T1    SVR  0.06 0.04\n",
            "4  Fold 5    T1    SVR  0.06 0.05\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# IMPORTA√á√ïES E CONFIGURA√á√ïES\n",
        "# ========================================================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "import keras_tuner as kt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Fixando seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ========================================================================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ========================================================================\n",
        "def gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae):\n",
        "    return pd.DataFrame({\n",
        "        'Fold': [f'Fold {i+1}' for i in range(len(fold_rmse))],\n",
        "        'Trafo': trafo,\n",
        "        'Modelo': modelo,\n",
        "        'RMSE': np.round(fold_rmse, 4),\n",
        "        'MAE': np.round(fold_mae, 4)\n",
        "    })\n",
        "\n",
        "def plotar_ultimo_fold(datas, y_real, y_pred, trafo, modelo, freq):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(datas, y_real, label='Real', color='blue')\n",
        "    plt.plot(datas, y_pred, label=f'Previsto ({modelo})', linestyle='--', color='orange')\n",
        "    plt.xlabel('Dia' if freq=='daily' else 'Hora')\n",
        "    plt.ylabel('Pot√™ncia Aparente (kVA)')\n",
        "    plt.title(f'Previs√£o √öltimo Fold - {modelo} ({trafo})')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    os.makedirs('plots', exist_ok=True)\n",
        "    plt.savefig(f'plots/PLOT_{modelo}_{trafo}_{freq}_ultimo_fold.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label='Data'):\n",
        "    datas_todas = pd.to_datetime(np.concatenate(lista_datas))\n",
        "    reais_todos = np.concatenate(lista_reais)\n",
        "    previstos_todos = np.concatenate(lista_previstos)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=reais_todos, mode='lines', name='Real', line=dict(color='blue')))\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=previstos_todos, mode='lines', name=f'Previsto ({modelo})', line=dict(color='orange', dash='dash')))\n",
        "    fig.update_layout(title=f'Previs√£o em Todos os Folds - {trafo} ({modelo})',\n",
        "                      xaxis_title=eixo_label, yaxis_title='Pot√™ncia Aparente', hovermode='x unified')\n",
        "    fig.show()\n",
        "\n",
        "# ========================================================================\n",
        "# HYPERPARAMS PARA RANDOMIZEDSEARCH\n",
        "# ========================================================================\n",
        "param_grids = {\n",
        "    'SVR': {\n",
        "        'C': [0.1, 1, 10, 100, 1000],\n",
        "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
        "        'epsilon': [0.001, 0.01, 0.1, 0.5]\n",
        "    },\n",
        "    'RFR': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'GBR': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    },\n",
        "    'XGB': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3,5,7]\n",
        "    },\n",
        "    'LGBM': {\n",
        "        'n_estimators': [50,100,200],\n",
        "        'learning_rate': [0.01,0.05,0.1],\n",
        "        'max_depth': [-1,3,5,7]\n",
        "    }\n",
        "}\n",
        "\n",
        "# ========================================================================\n",
        "# FUN√á√ÉO PRINCIPAL\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_auto(data, trafos_escolhidos, modelo, janela=None, epochs=20, batch_size=32, n_iter_search=10):\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "    data['datahora'] = pd.to_datetime(data['datahora'])\n",
        "    \n",
        "    delta = data['datahora'].diff().median()\n",
        "    if delta >= pd.Timedelta('1D'):\n",
        "        freq = 'daily'\n",
        "        if janela is None: janela = 30\n",
        "        eixo_label = 'Dia'\n",
        "    else:\n",
        "        freq = 'hourly'\n",
        "        if janela is None: janela = 24*7\n",
        "        eixo_label = 'Hora'\n",
        "        # Filtra s√≥ 2023 e 2024\n",
        "        data = data[(data['datahora'].dt.year >= 2023) & (data['datahora'].dt.year <= 2024)]\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\nüîπ Treinando {modelo} para {trafo} ({freq})...\")\n",
        "        df = data[data['id']==trafo].copy()\n",
        "        df = df[['datahora','S']].sort_values('datahora').dropna()\n",
        "        \n",
        "        # Janelas deslizantes\n",
        "        X, y, datas_janela = [], [], []\n",
        "        S_values = df['S'].values\n",
        "        datas = df['datahora'].values\n",
        "        for i in range(janela, len(df)):\n",
        "            X.append(S_values[i-janela:i])\n",
        "            y.append(S_values[i])\n",
        "            datas_janela.append(datas[i])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        datas_janela = np.array(datas_janela)\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']: X = X.reshape((X.shape[0], X.shape[1],1))\n",
        "        else: X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ====================\n",
        "            # MODELOS COM HYPERPARAMS\n",
        "            # ====================\n",
        "            if modelo in param_grids.keys(): # scikit-learn\n",
        "                base_model = {\n",
        "                    'SVR': SVR(),\n",
        "                    'RFR': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "                    'GBR': GradientBoostingRegressor(random_state=42),\n",
        "                    'XGB': XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
        "                    'LGBM': LGBMRegressor(random_state=42)\n",
        "                }[modelo]\n",
        "                search = RandomizedSearchCV(base_model, param_distributions=param_grids[modelo],\n",
        "                                            n_iter=n_iter_search, scoring='neg_mean_squared_error',\n",
        "                                            cv=TimeSeriesSplit(n_splits=3), n_jobs=-1, random_state=42)\n",
        "                search.fit(X_train, y_train)\n",
        "                best_model = search.best_estimator_\n",
        "                y_pred = best_model.predict(X_test)\n",
        "\n",
        "            else: # Redes neurais\n",
        "                def build_nn(hp):\n",
        "                    model = Sequential()\n",
        "                    if modelo=='LSTM':\n",
        "                        model.add(LSTM(units=hp.Int('units1', 20, 100, step=20), return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(LSTM(units=hp.Int('units2',20,100, step=20)))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    elif modelo=='CNN':\n",
        "                        model.add(Conv1D(filters=hp.Int('filters',32,128,step=32), kernel_size=2, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(Flatten())\n",
        "                        model.add(Dense(hp.Int('dense',10,50,step=10), activation='relu'))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    elif modelo=='CNN_LSTM':\n",
        "                        model.add(Conv1D(filters=hp.Int('filters',32,128,step=32), kernel_size=2, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(LSTM(units=hp.Int('units1',20,100,step=20), return_sequences=True))\n",
        "                        model.add(LSTM(units=hp.Int('units2',20,100,step=20)))\n",
        "                        model.add(Dense(1))\n",
        "                        model.compile(optimizer='adam', loss='mse')\n",
        "                    return model\n",
        "                tuner = kt.RandomSearch(build_nn, objective='val_loss', max_trials=5, overwrite=True)\n",
        "                tuner.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
        "                best_model = tuner.get_best_models(num_models=1)[0]\n",
        "                y_pred = best_model.predict(X_test).flatten()\n",
        "\n",
        "            # ====================\n",
        "            # M√âTRICAS\n",
        "            # ====================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "\n",
        "        # Plot do √∫ltimo fold\n",
        "        plotar_ultimo_fold(lista_datas[-1], lista_reais[-1], lista_previstos[-1], trafo, modelo, freq)\n",
        "\n",
        "        # Salva modelo final\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}.{'h5' if modelo in ['LSTM','CNN','CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']:\n",
        "            best_model.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(best_model, modelo_path)\n",
        "        print(f\"‚úÖ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # M√©tricas\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        # Plot todos folds\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label=eixo_label)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE M√©dio': np.round(np.mean(fold_rmse),4),\n",
        "            'MAE M√©dio': np.round(np.mean(fold_mae),4),\n",
        "            'RMSE √öltimo Fold': np.round(fold_rmse[-1],4),\n",
        "            'MAE √öltimo Fold': np.round(fold_mae[-1],4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# ========================================================================\n",
        "# USO\n",
        "# ========================================================================\n",
        "trafos = ['T1']\n",
        "resultados_SVR_daily = treinar_e_prever_modelo_auto(df_daily, trafos, modelo='SVR', janela=30, n_iter_search=10)\n",
        "resultados_SVR_hourly = treinar_e_prever_modelo_auto(df_hourly, trafos, modelo='SVR', janela=168, n_iter_search=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Lista de transformadores e modelos\n",
        "trafos = ['T1', 'T2']\n",
        "modelos = ['SVR', 'XGB', 'LGBM', 'GBR', 'LSTM', 'CNN', 'CNN_LSTM']\n",
        "\n",
        "# Diret√≥rio base onde est√£o os modelos\n",
        "base_dir = r\"G:\\Meu Drive\\Estudos\\Mestrado\\Github\\masters\\modelos\"\n",
        "\n",
        "# Dicion√°rio para armazenar os modelos carregados\n",
        "modelos_carregados = {}\n",
        "\n",
        "for trafo in trafos:\n",
        "    for modelo in modelos:\n",
        "        # Define a extens√£o correta\n",
        "        extensao = \"h5\" if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"] else \"pkl\"\n",
        "        caminho = os.path.join(base_dir, f\"{modelo}_{trafo}.{extensao}\")\n",
        "        \n",
        "        # Inicializa a chave no dicion√°rio\n",
        "        modelos_carregados[(modelo, trafo)] = None\n",
        "        \n",
        "        # Carrega apenas se o arquivo existir\n",
        "        if os.path.exists(caminho):\n",
        "            if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"]:\n",
        "                modelos_carregados[(modelo, trafo)] = load_model(caminho)\n",
        "            else:\n",
        "                modelos_carregados[(modelo, trafo)] = joblib.load(caminho)\n",
        "            print(f\"‚úÖ Modelo carregado: {caminho}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Arquivo n√£o encontrado, ignorando: {caminho}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos analisar seus dados originais para entender a estrutura\n",
        "print(\"=== ANALISANDO DADOS ORIGINAIS ===\")\n",
        "print(f\"Shape do df_daily: {df_daily.shape}\")\n",
        "print(f\"Colunas: {df_daily.columns.tolist()}\")\n",
        "print(f\"Tipos de dados:\\n{df_daily.dtypes}\")\n",
        "\n",
        "# Ver um exemplo dos dados do T1\n",
        "print(\"\\n=== DADOS DO TRAFO T1 ===\")\n",
        "df_t1 = df_daily[df_daily['id'] == 'T1'].copy()\n",
        "print(f\"Quantidade de dados T1: {len(df_t1)}\")\n",
        "print(f\"Per√≠odo: {df_t1['datahora'].min()} at√© {df_t1['datahora'].max()}\")\n",
        "print(f\"Primeiras linhas T1:\")\n",
        "print(df_t1.head())\n",
        "\n",
        "# Ver a distribui√ß√£o da vari√°vel target 'S'\n",
        "print(f\"\\nEstat√≠sticas da Pot√™ncia Aparente (S):\")\n",
        "print(df_t1['S'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TREINNAMENTO ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_hourly = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/transformers_dataset.csv\"\n",
        "df_hourly = pd.read_csv(url_hourly,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
        "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando treinamento com configura√ß√µes otimizadas...\n",
            "\n",
            "üìä Treinando com dados DI√ÅRIOS (configura√ß√£o padr√£o)...\n",
            "\n",
            "üîπ Treinando SVR para T1 (daily)...\n",
            "   Fold 1: RMSE=0.0473, MAE=0.0313\n",
            "   Fold 2: RMSE=0.0413, MAE=0.0294\n",
            "   Fold 3: RMSE=0.0362, MAE=0.0268\n",
            "   Fold 4: RMSE=0.0477, MAE=0.0326\n",
            "   Fold 5: RMSE=0.0527, MAE=0.0398\n",
            "‚úÖ Modelo salvo em: modelos/SVR_T1_daily.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1    SVR  0.05 0.03\n",
            "1  Fold 2    T1    SVR  0.04 0.03\n",
            "2  Fold 3    T1    SVR  0.04 0.03\n",
            "3  Fold 4    T1    SVR  0.05 0.03\n",
            "4  Fold 5    T1    SVR  0.05 0.04\n",
            "\n",
            "‚úÖ Todos os treinamentos conclu√≠dos!\n",
            "\n",
            "Resultados Hor√°rios:\n",
            "  Trafo Modelo  RMSE M√©dio  MAE M√©dio  RMSE √öltimo Fold  MAE √öltimo Fold\n",
            "0    T1    SVR        0.06       0.05              0.06             0.05\n",
            "\n",
            "Resultados Di√°rios:\n",
            "  Trafo Modelo Frequ√™ncia  RMSE M√©dio  MAE M√©dio  RMSE √öltimo Fold  \\\n",
            "0    T1    SVR      daily        0.04       0.03              0.05   \n",
            "\n",
            "   MAE √öltimo Fold  \n",
            "0             0.04  \n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# IMPORTA√á√ïES E CONFIGURA√á√ïES\n",
        "# ========================================================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Fixando seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ========================================================================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ========================================================================\n",
        "def gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae):\n",
        "    return pd.DataFrame({\n",
        "        'Fold': [f'Fold {i+1}' for i in range(len(fold_rmse))],\n",
        "        'Trafo': trafo,\n",
        "        'Modelo': modelo,\n",
        "        'RMSE': np.round(fold_rmse, 4),\n",
        "        'MAE': np.round(fold_mae, 4)\n",
        "    })\n",
        "\n",
        "def plotar_ultimo_fold(datas, y_real, y_pred, trafo, modelo, freq):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(datas, y_real, label='Real', color='blue')\n",
        "    plt.plot(datas, y_pred, label=f'Previsto ({modelo})', linestyle='--', color='orange')\n",
        "    plt.xlabel('Dia' if freq=='daily' else 'Hora')\n",
        "    plt.ylabel('Pot√™ncia Aparente (kVA)')\n",
        "    plt.title(f'Previs√£o √öltimo Fold - {modelo} ({trafo})')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    os.makedirs('plots', exist_ok=True)\n",
        "    plt.savefig(f'plots/PLOT_{modelo}_{trafo}_{freq}_ultimo_fold.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label='Data'):\n",
        "    datas_todas = pd.to_datetime(np.concatenate(lista_datas))\n",
        "    reais_todos = np.concatenate(lista_reais)\n",
        "    previstos_todos = np.concatenate(lista_previstos)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=reais_todos, mode='lines', name='Real', line=dict(color='blue')))\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=previstos_todos, mode='lines', name=f'Previsto ({modelo})', line=dict(color='orange', dash='dash')))\n",
        "    fig.update_layout(title=f'Previs√£o em Todos os Folds - {trafo} ({modelo})',\n",
        "                      xaxis_title=eixo_label, yaxis_title='Pot√™ncia Aparente', hovermode='x unified')\n",
        "    fig.show()\n",
        "\n",
        "# ========================================================================\n",
        "# HYPERPARAMS OTIMIZADOS\n",
        "# ========================================================================\n",
        "param_grids_base = {\n",
        "    'SVR': {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': ['scale', 'auto', 0.01, 0.1],\n",
        "        'epsilon': [0.01, 0.1, 0.5]\n",
        "    },\n",
        "    'RFR': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [5, 10, 15],\n",
        "        'min_samples_split': [2, 5]\n",
        "    },\n",
        "    'GBR': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    },\n",
        "    'XGB': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    },\n",
        "    'LGBM': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_param_grids_por_freq(freq, modelo):\n",
        "    \"\"\"Retorna grid de par√¢metros baseado na frequ√™ncia dos dados\"\"\"\n",
        "    base_params = param_grids_base[modelo].copy()\n",
        "    \n",
        "    if freq == 'hourly':  # Dados hor√°rios - grids mais simples\n",
        "        if modelo == 'SVR':\n",
        "            base_params['C'] = [1, 10]\n",
        "            base_params['gamma'] = ['scale', 0.01]\n",
        "            base_params['epsilon'] = [0.1]\n",
        "        elif modelo in ['RFR', 'GBR', 'XGB', 'LGBM']:\n",
        "            base_params['n_estimators'] = [50, 100]  # Menos √°rvores\n",
        "    return base_params\n",
        "\n",
        "# ========================================================================\n",
        "# FUN√á√ÉO PRINCIPAL OTIMIZADA\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_auto_otimizado(data, trafos_escolhidos, modelo, janela=None, epochs=15, batch_size=32, n_iter_search=5):\n",
        "    \"\"\"Vers√£o otimizada da fun√ß√£o principal\"\"\"\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "    data['datahora'] = pd.to_datetime(data['datahora'])\n",
        "    \n",
        "    # Determina frequ√™ncia e configura√ß√µes\n",
        "    delta = data['datahora'].diff().median()\n",
        "    if delta >= pd.Timedelta('1D'):\n",
        "        freq = 'daily'\n",
        "        if janela is None: janela = 30\n",
        "        eixo_label = 'Dia'\n",
        "    else:\n",
        "        freq = 'hourly'\n",
        "        if janela is None: janela = 24*3  # 3 dias em vez de 7\n",
        "        eixo_label = 'Hora'\n",
        "        # Filtra s√≥ 2023 e 2024 de forma mais eficiente\n",
        "        data = data[data['datahora'].dt.year.isin([2023, 2024])].copy()\n",
        "\n",
        "    # PR√â-COMPUTA√á√ÉO: Criar dicion√°rio com dados de cada trafo\n",
        "    dados_trafos = {}\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df_trafo = data[data['id']==trafo][['datahora','S']].sort_values('datahora').dropna()\n",
        "        dados_trafos[trafo] = {\n",
        "            'S_values': df_trafo['S'].values,\n",
        "            'datas': df_trafo['datahora'].values\n",
        "        }\n",
        "\n",
        "    # Configura√ß√µes espec√≠ficas por frequ√™ncia\n",
        "    if freq == 'hourly':\n",
        "        n_iter_search = max(2, n_iter_search // 2)  # Menos itera√ß√µes\n",
        "        epochs = min(10, epochs)  # Menos epochs\n",
        "        batch_size = min(64, batch_size)  # Batch menor\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\nüîπ Treinando {modelo} para {trafo} ({freq})...\")\n",
        "        \n",
        "        # Uso dos dados pr√©-computados\n",
        "        S_values = dados_trafos[trafo]['S_values']\n",
        "        datas = dados_trafos[trafo]['datas']\n",
        "        \n",
        "        # Cria√ß√£o MAIS EFICIENTE das janelas usando sliding_window_view\n",
        "        n_samples = len(S_values) - janela\n",
        "        if n_samples <= 0:\n",
        "            print(f\"‚ö†Ô∏è Dados insuficientes para {trafo}. Pulando...\")\n",
        "            continue\n",
        "            \n",
        "        X = np.lib.stride_tricks.sliding_window_view(S_values, janela)[:n_samples]\n",
        "        y = S_values[janela:janela + n_samples]\n",
        "        datas_janela = datas[janela:janela + n_samples]\n",
        "        \n",
        "        # Reshape para modelos\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']: \n",
        "            X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "        else: \n",
        "            X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ====================\n",
        "            # MODELOS COM HYPERPARAMS OTIMIZADOS\n",
        "            # ====================\n",
        "            if modelo in param_grids_base.keys(): # scikit-learn\n",
        "                param_grid_freq = get_param_grids_por_freq(freq, modelo)\n",
        "                \n",
        "                base_model = {\n",
        "                    'SVR': SVR(),\n",
        "                    'RFR': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "                    'GBR': GradientBoostingRegressor(random_state=42),\n",
        "                    'XGB': XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
        "                    'LGBM': LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)  # Silencioso\n",
        "                }[modelo]\n",
        "                \n",
        "                # RandomizedSearch mais r√°pido\n",
        "                search = RandomizedSearchCV(\n",
        "                    base_model, \n",
        "                    param_distributions=param_grid_freq,\n",
        "                    n_iter=n_iter_search, \n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=TimeSeriesSplit(n_splits=2),  # Menos folds de valida√ß√£o\n",
        "                    n_jobs=1 if modelo in ['SVR'] else -1,  # SVR n√£o paraleliza bem\n",
        "                    random_state=42,\n",
        "                    verbose=0  # Silencioso\n",
        "                )\n",
        "                search.fit(X_train, y_train)\n",
        "                best_model = search.best_estimator_\n",
        "                y_pred = best_model.predict(X_test)\n",
        "\n",
        "            else: # Redes neurais\n",
        "                def build_nn_otimizada(hp):\n",
        "                    model = Sequential()\n",
        "                    \n",
        "                    # Configura√ß√µes baseadas na frequ√™ncia\n",
        "                    units_multiplier = 0.7 if freq == 'hourly' else 1\n",
        "                    \n",
        "                    if modelo == 'LSTM':\n",
        "                        model.add(LSTM(\n",
        "                            units=hp.Int('units1', \n",
        "                                       int(20*units_multiplier), \n",
        "                                       int(80*units_multiplier), \n",
        "                                       step=20), \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(Dense(1))\n",
        "                    elif modelo == 'CNN':\n",
        "                        model.add(Conv1D(\n",
        "                            filters=hp.Int('filters', 32, 64, step=32), \n",
        "                            kernel_size=2, \n",
        "                            activation='relu', \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(Flatten())\n",
        "                        model.add(Dense(1))\n",
        "                    elif modelo == 'CNN_LSTM':\n",
        "                        model.add(Conv1D(\n",
        "                            filters=32, \n",
        "                            kernel_size=2, \n",
        "                            activation='relu', \n",
        "                            input_shape=(X_train.shape[1], 1)\n",
        "                        ))\n",
        "                        model.add(MaxPooling1D(2))\n",
        "                        model.add(LSTM(\n",
        "                            units=hp.Int('units1', 20, 60, step=20)\n",
        "                        ))\n",
        "                        model.add(Dense(1))\n",
        "                    \n",
        "                    model.compile(optimizer='adam', loss='mse')\n",
        "                    return model\n",
        "                \n",
        "                # Early stopping para redes neurais\n",
        "                early_stop = EarlyStopping(\n",
        "                    monitor='val_loss', \n",
        "                    patience=3, \n",
        "                    restore_best_weights=True\n",
        "                )\n",
        "                \n",
        "                tuner = kt.RandomSearch(\n",
        "                    build_nn_otimizada,\n",
        "                    objective='val_loss',\n",
        "                    max_trials=3,  # Menos trials\n",
        "                    overwrite=True,\n",
        "                    executions_per_trial=1,\n",
        "                    directory='keras_tuner',\n",
        "                    project_name=f'{modelo}_{trafo}_{freq}'\n",
        "                )\n",
        "                \n",
        "                tuner.search(\n",
        "                    X_train, y_train, \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stop],\n",
        "                    verbose=0\n",
        "                )\n",
        "                \n",
        "                best_model = tuner.get_best_models(num_models=1)[0]\n",
        "                y_pred = best_model.predict(X_test).flatten()\n",
        "\n",
        "            # ====================\n",
        "            # M√âTRICAS\n",
        "            # ====================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "            \n",
        "            print(f\"   Fold {fold_idx+1}: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "        # Plot do √∫ltimo fold\n",
        "        plotar_ultimo_fold(lista_datas[-1], lista_reais[-1], lista_previstos[-1], trafo, modelo, freq)\n",
        "\n",
        "        # Salva modelo final\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}_{freq}.{'h5' if modelo in ['LSTM','CNN','CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM','CNN','CNN_LSTM']:\n",
        "            best_model.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(best_model, modelo_path)\n",
        "        print(f\"‚úÖ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # M√©tricas\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        # Plot todos folds\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo, eixo_label=eixo_label)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'Frequ√™ncia': freq,\n",
        "            'RMSE M√©dio': np.round(np.mean(fold_rmse),4),\n",
        "            'MAE M√©dio': np.round(np.mean(fold_mae),4),\n",
        "            'RMSE √öltimo Fold': np.round(fold_rmse[-1],4),\n",
        "            'MAE √öltimo Fold': np.round(fold_mae[-1],4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# ========================================================================\n",
        "# USO OTIMIZADO\n",
        "# ========================================================================\n",
        "trafos = ['T1']\n",
        "\n",
        "print(\"üöÄ Iniciando treinamento com configura√ß√µes otimizadas...\")\n",
        "\n",
        "# Para dados di√°rios - configura√ß√µes normais\n",
        "print(\"\\nüìä Treinando com dados DI√ÅRIOS (configura√ß√£o padr√£o)...\")\n",
        "\n",
        "resultados_SVR_daily = treinar_e_prever_modelo_auto_otimizado(\n",
        "    df_daily, \n",
        "    trafos, \n",
        "    'SVR', \n",
        "    janela=30,\n",
        "    n_iter_search=5,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Todos os treinamentos conclu√≠dos!\")\n",
        "print(\"\\nResultados Hor√°rios:\")\n",
        "print(resultados_SVR_hourly)\n",
        "print(\"\\nResultados Di√°rios:\")\n",
        "print(resultados_SVR_daily)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîπ Treinando LGBM para T1 (hourly)...\n",
            "   Fold 1: RMSE=0.0509, MAE=0.0358\n",
            "   Fold 2: RMSE=0.0609, MAE=0.0439\n",
            "   Fold 3: RMSE=0.0505, MAE=0.0352\n",
            "   Fold 4: RMSE=0.0495, MAE=0.0332\n",
            "   Fold 5: RMSE=0.0576, MAE=0.0392\n",
            "‚úÖ Modelo salvo em: modelos/LGBM_T1_hourly.pkl\n",
            "     Fold Trafo Modelo  RMSE  MAE\n",
            "0  Fold 1    T1   LGBM  0.05 0.04\n",
            "1  Fold 2    T1   LGBM  0.06 0.04\n",
            "2  Fold 3    T1   LGBM  0.05 0.04\n",
            "3  Fold 4    T1   LGBM  0.05 0.03\n",
            "4  Fold 5    T1   LGBM  0.06 0.04\n"
          ]
        }
      ],
      "source": [
        "# Teste r√°pido com dados hor√°rios\n",
        "resultados = treinar_e_prever_modelo_auto_otimizado(\n",
        "    df_hourly, \n",
        "    ['T1'], \n",
        "    'LGBM',  # Mais r√°pido que SVR\n",
        "    janela=24*3, \n",
        "    n_iter_search=2,\n",
        "    epochs=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CRIANDO FEATURES SAZONAIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Di√°rio, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_daily(df_daily):\n",
        "    df_featured_daily = df_daily.copy()\n",
        "        \n",
        "    # Features para dados di√°rios\n",
        "    df_featured_daily['datahora'] = pd.to_datetime(df_featured_daily['datahora'])\n",
        "    df_featured_daily = df_featured_daily.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_daily['day_of_week'] = df_featured_daily['datahora'].dt.dayofweek\n",
        "    df_featured_daily['month'] = df_featured_daily['datahora'].dt.month\n",
        "    df_featured_daily['year'] = df_featured_daily['datahora'].dt.year\n",
        "    df_featured_daily['is_weekend'] = (df_featured_daily['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features c√≠clicas di√°rias\n",
        "    df_featured_daily['sin_day_of_week'] = np.sin(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['cos_day_of_week'] = np.cos(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['sin_month'] = np.sin(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    df_featured_daily['cos_month'] = np.cos(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    \n",
        "    # Lags di√°rios (sazonais)\n",
        "    for lag in [1, 7, 30, 365]:  # 1 dia, 1 semana, 1 m√™s, 1 ano\n",
        "        df_featured_daily[f'S{lag}'] = df_featured_daily.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # M√©dias m√≥veis di√°rias\n",
        "    for window in [7, 30, 90]:  # 1 semana, 1 m√™s, 3 meses\n",
        "        df_featured_daily[f'S_rolling_mean_{window}'] = df_featured_daily.groupby('id')['S'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).mean())\n",
        "        \n",
        "    return df_featured_daily\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados di√°rios...\")\n",
        "daily_features = criar_features_daily(df_daily)\n",
        "daily_features\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"‚úÖ Features di√°rias criadas com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hora em Hora, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_hourly(df_hourly):\n",
        "    # \"\"\"Cria features espec√≠ficas para cada modo\"\"\"    \n",
        "    df_featured_hourly = df_hourly.copy()\n",
        "\n",
        "    # Features para dados hor√°rios\n",
        "    df_featured_hourly['datahora'] = pd.to_datetime(df_featured_hourly['datahora'])\n",
        "    df_featured_hourly = df_featured_hourly.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_hourly['hour'] = df_featured_hourly['datahora'].dt.hour\n",
        "    df_featured_hourly['day_of_week'] = df_featured_hourly['datahora'].dt.dayofweek\n",
        "    df_featured_hourly['is_weekend'] = (df_featured_hourly['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features c√≠clicas hor√°rias\n",
        "    df_featured_hourly['sin_hour'] = np.sin(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    df_featured_hourly['cos_hour'] = np.cos(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    \n",
        "    # Lags hor√°rios\n",
        "    for lag in [1, 24, 168]:  # 1h, 1 dia, 1 semana\n",
        "        df_featured_hourly[f'S_lag_{lag}'] = df_featured_hourly.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # M√©dias m√≥veis hor√°rias\n",
        "    df_featured_hourly['S_rolling_mean_24'] = df_featured_hourly.groupby('id')['S'].transform(\n",
        "        lambda x: x.rolling(24, min_periods=1).mean())\n",
        "        \n",
        "        \n",
        "    return df_featured_hourly\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados hor√°rios...\")\n",
        "hourly_features = criar_features_hourly(df_hourly)\n",
        "\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"‚úÖ Features hor√°rias criadas com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TREINANDO MULTI-FEATURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "# ========================================================================\n",
        "# FUN√á√ÉO PRINCIPAL DE TREINAMENTO E PREVIS√ÉO (ATUALIZADA)\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo_ft(data, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para treinar e prever modelos de s√©ries temporais com m√∫ltiplas features.\n",
        "    \n",
        "    Par√¢metros:\n",
        "        data (DataFrame): dataframe com colunas ['id', 'datahora', 'S'] + features extras\n",
        "        trafos_escolhidos (list): lista de transformadores a treinar\n",
        "        modelo (str): nome do modelo ('SVR', 'RFR', 'GBR', 'XGB', 'LGBM', 'LSTM', 'CNN', 'CNN_LSTM')\n",
        "        janela (int): tamanho da janela deslizante (n√∫mero de passos anteriores)\n",
        "        epochs (int): n√∫mero de √©pocas (para redes neurais)\n",
        "        batch_size (int): tamanho do batch (para redes neurais)\n",
        "    \n",
        "    Retorna:\n",
        "        DataFrame com as m√©tricas m√©dias por trafo.\n",
        "    \"\"\"\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\nüîπ Treinando {modelo} para {trafo}...\")\n",
        "\n",
        "        # ======================\n",
        "        # 1. Prepara√ß√£o dos dados\n",
        "        # ======================\n",
        "        df = data[data['id'] == trafo].copy()\n",
        "        df = df.sort_values('datahora').dropna().reset_index(drop=True)\n",
        "\n",
        "        # Seleciona todas as colunas num√©ricas exceto 'id', 'datahora' e 'S'\n",
        "        feature_cols = [c for c in df.columns if c not in ['id', 'datahora', 'S']]\n",
        "        target_col = 'S'\n",
        "\n",
        "        X_raw = df[feature_cols].values\n",
        "        y_raw = df[target_col].values\n",
        "        datas = df['datahora'].values\n",
        "\n",
        "        # Cria janelas deslizantes\n",
        "        X, y, datas_janela = [], [], []\n",
        "        for i in range(janela, len(df)):\n",
        "            X.append(X_raw[i-janela:i])   # entrada: janela com features\n",
        "            y.append(y_raw[i])            # sa√≠da: valor atual\n",
        "            datas_janela.append(datas[i]) # datas para plot\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        datas_janela = np.array(datas_janela)\n",
        "\n",
        "        # Ajuste de shape\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))  # (amostras, timesteps, features)\n",
        "        else:\n",
        "            X = X.reshape(X.shape[0], -1)  # achata janelas + features\n",
        "\n",
        "        # ======================\n",
        "        # 2. Cross-validation temporal\n",
        "        # ======================\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ======================\n",
        "            # 3. Inicializa modelo\n",
        "            # ======================\n",
        "            if modelo == 'SVR':\n",
        "                regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "            elif modelo == 'RFR':\n",
        "                regressor = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
        "            elif modelo == 'GBR':\n",
        "                regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'LGBM':\n",
        "                regressor = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'XGB':\n",
        "                regressor = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
        "            elif modelo == 'LSTM':\n",
        "                regressor = Sequential([\n",
        "                    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    Flatten(),\n",
        "                    Dense(50, activation='relu'),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN_LSTM':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    LSTM(50, return_sequences=True),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "            # ======================\n",
        "            # 4. Treinamento\n",
        "            # ======================\n",
        "            if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "                regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "                y_pred = regressor.predict(X_test)\n",
        "            else:\n",
        "                regressor.fit(X_train, y_train)\n",
        "                y_pred = regressor.predict(X_test)\n",
        "\n",
        "            # ======================\n",
        "            # 5. Avalia√ß√£o\n",
        "            # ======================\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "\n",
        "            datas_finais = datas_janela[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "\n",
        "            if fold_idx == 4:\n",
        "                plotar_resultados(datas_finais, y_test, y_pred, trafo, modelo)\n",
        "\n",
        "        # ======================\n",
        "        # 6. Salva modelo final\n",
        "        # ======================\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}.{'h5' if modelo in ['LSTM', 'CNN', 'CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            regressor.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(regressor, modelo_path)\n",
        "        print(f\"‚úÖ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        # ======================\n",
        "        # 7. M√©tricas e plots\n",
        "        # ======================\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE M√©dio': np.round(np.mean(fold_rmse), 4),\n",
        "            'MAE M√©dio': np.round(np.mean(fold_mae), 4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trafos = ['T1']\n",
        "\n",
        "# resultados_XGB = treinar_e_prever_modelo(df_daily, trafos, modelo='XGB', janela=365)\n",
        "resultados_XGB_ft = treinar_e_prever_modelo_ft(daily_features, trafos, modelo='XGB', janela=365)\n",
        "# resultados_LGBM = treinar_e_prever_modelo(daily_features, trafos, modelo='LGBM', janela=365)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
