{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJDwuasZi9i2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_hourly = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/transformers_dataset.csv\"\n",
        "df_hourly = pd.read_csv(url_hourly,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
        "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n",
        "\n",
        "# df_count = df_daily.groupby('id').count()\n",
        "\n",
        "# df_count = df_count.sort_values('datahora').tail(41).reset_index() # esses são os trafos com mais de 97,5% de linhas preenchidas\n",
        "# trafos_escolhidos = df_count['id'].unique().tolist()\n",
        "# df_filtrado = df_daily[df_daily['id'].isin(trafos_escolhidos)]\n",
        "\n",
        "# fig_aparente = px.line(df_filtrado, x='datahora', y='S', color='id',\n",
        "#                        title='Potência Aparente ao Longo do Tempo por Transformador',\n",
        "#                        labels={'S': 'Potência Aparente (kVA)', 'Dia': 'Data'})\n",
        "\n",
        "# fig_aparente.show()\n",
        "# fig_aparente.write_html(\"Demanda ao longo do tempo - IQR.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8xHrY-i9jH"
      },
      "source": [
        "#### Algoritmo de Aprendizado de Máquina - Pico Diário, 1 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw3U9O2vi9jK"
      },
      "outputs": [],
      "source": [
        "# ========================================================================\n",
        "# IMPORTAÇÕES E CONFIGURAÇÕES\n",
        "# ========================================================================\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "import joblib\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Fixando seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ========================================================================\n",
        "def gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae):\n",
        "    return pd.DataFrame({\n",
        "        'Fold': [f'Fold {i+1}' for i in range(len(fold_rmse))],\n",
        "        'Trafo': trafo,\n",
        "        'Modelo': modelo,\n",
        "        'RMSE': np.round(fold_rmse, 4),\n",
        "        'MAE': np.round(fold_mae, 4)\n",
        "    })\n",
        "\n",
        "\n",
        "def plotar_resultados(datas, y_real, y_pred, trafo, modelo):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(datas, y_real, label='Real', color='blue')\n",
        "    plt.plot(datas, y_pred, label=f'Previsto ({modelo})', linestyle='--', color='orange')\n",
        "    plt.xlabel('Data', fontsize=16)\n",
        "    plt.ylabel('Potência Aparente (kVA)', fontsize=16)\n",
        "    plt.title(f'Previsão - {modelo} ({trafo})', fontsize=18)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    os.makedirs('plots', exist_ok=True)\n",
        "    plt.savefig(f'plots/PLOT_{modelo}_{trafo}.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo):\n",
        "    datas_todas = pd.to_datetime(np.concatenate(lista_datas))\n",
        "    reais_todos = np.concatenate(lista_reais)\n",
        "    previstos_todos = np.concatenate(lista_previstos)\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=reais_todos, mode='lines', name='Real', line=dict(color='blue')))\n",
        "    fig.add_trace(go.Scatter(x=datas_todas, y=previstos_todos, mode='lines', name=f'Previsto ({modelo})', line=dict(color='orange', dash='dash')))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'Previsão em Todos os Folds - {trafo} ({modelo})',\n",
        "        xaxis_title='Data',\n",
        "        yaxis_title='Potência Aparente',\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "# ========================================================================\n",
        "# FUNÇÃO PRINCIPAL DE TREINAMENTO E PREVISÃO\n",
        "# ========================================================================\n",
        "def treinar_e_prever_modelo(data, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    resultados = []\n",
        "    os.makedirs('modelos', exist_ok=True)\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        print(f\"\\n🔹 Treinando {modelo} para {trafo}...\")\n",
        "\n",
        "        df = data[data['id'] == trafo].copy()\n",
        "        df = df[['datahora', 'S']].set_index('datahora').sort_index()\n",
        "\n",
        "        # Cria janelas deslizantes\n",
        "        X, y = [], []\n",
        "        for i in range(janela, len(df)):\n",
        "            X.append(df.iloc[i-janela:i].values)\n",
        "            y.append(df.iloc[i, 0])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "\n",
        "        # Ajuste de shape para redes neurais\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
        "\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        fold_rmse, fold_mae = [], []\n",
        "        lista_datas, lista_reais, lista_previstos = [], [], []\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # Inicializa modelo\n",
        "            if modelo == 'SVR':\n",
        "                regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "            elif modelo == 'RFR':\n",
        "                regressor = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
        "            elif modelo == 'GBR':\n",
        "                regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'LGBM':\n",
        "                regressor = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'XGB':\n",
        "                regressor = XGBRegressor(n_estimators=100, random_state=42)\n",
        "            elif modelo == 'LSTM':\n",
        "                regressor = Sequential([\n",
        "                    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    Flatten(),\n",
        "                    Dense(50, activation='relu'),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "            elif modelo == 'CNN_LSTM':\n",
        "                regressor = Sequential([\n",
        "                    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    MaxPooling1D(2),\n",
        "                    LSTM(50, return_sequences=True),\n",
        "                    LSTM(50),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                regressor.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "            # Treinamento\n",
        "            if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "                regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "                y_pred = regressor.predict(X_test)\n",
        "            else:\n",
        "                regressor.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "                y_pred = regressor.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "            # Métricas\n",
        "            rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mae.append(mae)\n",
        "\n",
        "            datas_finais = df.index[test_idx]\n",
        "            lista_datas.append(datas_finais)\n",
        "            lista_reais.append(y_test)\n",
        "            lista_previstos.append(y_pred)\n",
        "\n",
        "            if fold_idx == 4:\n",
        "                plotar_resultados(datas_finais, y_test, y_pred, trafo, modelo)\n",
        "\n",
        "        # Salva modelo final\n",
        "        modelo_path = f\"modelos/{modelo}_{trafo}.{'h5' if modelo in ['LSTM', 'CNN', 'CNN_LSTM'] else 'pkl'}\"\n",
        "        if modelo in ['LSTM', 'CNN', 'CNN_LSTM']:\n",
        "            regressor.save(modelo_path)\n",
        "        else:\n",
        "            joblib.dump(regressor, modelo_path)\n",
        "        print(f\"✅ Modelo salvo em: {modelo_path}\")\n",
        "\n",
        "        df_metricas = gerar_tabela_metricas_por_fold(trafo, modelo, fold_rmse, fold_mae)\n",
        "        print(df_metricas)\n",
        "\n",
        "        plotar_todos_folds(lista_datas, lista_reais, lista_previstos, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE Médio': np.round(np.mean(fold_rmse), 4),\n",
        "            'MAE Médio': np.round(np.mean(fold_mae), 4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "\n",
        "# ========================================================================\n",
        "# df_daily deve estar carregado e normalizado\n",
        "trafos = ['T1', 'T2'] \n",
        "# resultados_SVR = treinar_e_prever_modelo(df_daily, trafos, modelo='SVR', janela=365)\n",
        "# resultados_LSTM = treinar_e_prever_modelo(df_daily, trafos, modelo='LSTM', janela=365)\n",
        "# resultados_CNN = treinar_e_prever_modelo(df_daily, trafos, modelo='CNN', janela=365)\n",
        "# resultados_RFR = treinar_e_prever_modelo(df_daily, trafos, modelo='RFR', janela=365)\n",
        "resultados_GBR = treinar_e_prever_modelo(df_daily, trafos, modelo='GBR', janela=365)\n",
        "resultados_XBR = treinar_e_prever_modelo(df_daily, trafos, modelo='XBR', janela=365)\n",
        "resultados_LGBM = treinar_e_prever_modelo(df_daily, trafos, modelo='LGBM', janela=365)\n",
        "resultados_CNN_LSTM = treinar_e_prever_modelo(df_daily, trafos, modelo='CNN_LSTM', janela=365)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Lista de transformadores e modelos\n",
        "trafos = ['T1', 'T2']\n",
        "modelos = ['SVR', 'LSTM', 'CNN', 'CNN_LSTM']\n",
        "\n",
        "# Diretório base onde estão os modelos\n",
        "base_dir = r\"G:\\Meu Drive\\Estudos\\Mestrado\\Github\\masters\\modelos\"\n",
        "\n",
        "# Dicionário para armazenar os modelos carregados\n",
        "modelos_carregados = {}\n",
        "\n",
        "for trafo in trafos:\n",
        "    for modelo in modelos:\n",
        "        # Define a extensão correta\n",
        "        extensao = \"h5\" if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"] else \"pkl\"\n",
        "        caminho = os.path.join(base_dir, f\"{modelo}_{trafo}.{extensao}\")\n",
        "        \n",
        "        # Inicializa a chave no dicionário\n",
        "        modelos_carregados[(modelo, trafo)] = None\n",
        "        \n",
        "        # Carrega apenas se o arquivo existir\n",
        "        if os.path.exists(caminho):\n",
        "            if modelo in [\"LSTM\", \"CNN\", \"CNN_LSTM\"]:\n",
        "                modelos_carregados[(modelo, trafo)] = load_model(caminho)\n",
        "            else:\n",
        "                modelos_carregados[(modelo, trafo)] = joblib.load(caminho)\n",
        "            print(f\"✅ Modelo carregado: {caminho}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Arquivo não encontrado, ignorando: {caminho}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos analisar seus dados originais para entender a estrutura\n",
        "print(\"=== ANALISANDO DADOS ORIGINAIS ===\")\n",
        "print(f\"Shape do df_daily: {df_daily.shape}\")\n",
        "print(f\"Colunas: {df_daily.columns.tolist()}\")\n",
        "print(f\"Tipos de dados:\\n{df_daily.dtypes}\")\n",
        "\n",
        "# Ver um exemplo dos dados do T1\n",
        "print(\"\\n=== DADOS DO TRAFO T1 ===\")\n",
        "df_t1 = df_daily[df_daily['id'] == 'T1'].copy()\n",
        "print(f\"Quantidade de dados T1: {len(df_t1)}\")\n",
        "print(f\"Período: {df_t1['datahora'].min()} até {df_t1['datahora'].max()}\")\n",
        "print(f\"Primeiras linhas T1:\")\n",
        "print(df_t1.head())\n",
        "\n",
        "# Ver a distribuição da variável target 'S'\n",
        "print(f\"\\nEstatísticas da Potência Aparente (S):\")\n",
        "print(df_t1['S'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diário, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_daily(df_daily):\n",
        "    df_featured_daily = df_daily.copy()\n",
        "        \n",
        "    # Features para dados diários\n",
        "    df_featured_daily['datahora'] = pd.to_datetime(df_featured_daily['datahora'])\n",
        "    df_featured_daily = df_featured_daily.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_daily['day_of_week'] = df_featured_daily['datahora'].dt.dayofweek\n",
        "    df_featured_daily['month'] = df_featured_daily['datahora'].dt.month\n",
        "    df_featured_daily['year'] = df_featured_daily['datahora'].dt.year\n",
        "    df_featured_daily['is_weekend'] = (df_featured_daily['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features cíclicas diárias\n",
        "    df_featured_daily['sin_day_of_week'] = np.sin(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['cos_day_of_week'] = np.cos(2 * np.pi * df_featured_daily['day_of_week'] / 7)\n",
        "    df_featured_daily['sin_month'] = np.sin(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    df_featured_daily['cos_month'] = np.cos(2 * np.pi * df_featured_daily['month'] / 12)\n",
        "    \n",
        "    # Lags diários (sazonais)\n",
        "    for lag in [1, 7, 30, 365]:  # 1 dia, 1 semana, 1 mês, 1 ano\n",
        "        df_featured_daily[f'S{lag}'] = df_featured_daily.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # Médias móveis diárias\n",
        "    for window in [7, 30, 90]:  # 1 semana, 1 mês, 3 meses\n",
        "        df_featured_daily[f'S_rolling_mean_{window}'] = df_featured_daily.groupby('id')['S'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).mean())\n",
        "        \n",
        "    return df_featured_daily\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados diários...\")\n",
        "daily_features = criar_features_daily(df_daily)\n",
        "daily_features\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"✅ Features diárias criadas com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hora em Hora, multi-feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def criar_features_hourly(df_hourly):\n",
        "    # \"\"\"Cria features específicas para cada modo\"\"\"    \n",
        "    df_featured_hourly = df_hourly.copy()\n",
        "\n",
        "    # Features para dados horários\n",
        "    df_featured_hourly['datahora'] = pd.to_datetime(df_featured_hourly['datahora'])\n",
        "    df_featured_hourly = df_featured_hourly.sort_values(['id', 'datahora'])\n",
        "    \n",
        "    df_featured_hourly['hour'] = df_featured_hourly['datahora'].dt.hour\n",
        "    df_featured_hourly['day_of_week'] = df_featured_hourly['datahora'].dt.dayofweek\n",
        "    df_featured_hourly['is_weekend'] = (df_featured_hourly['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Features cíclicas horárias\n",
        "    df_featured_hourly['sin_hour'] = np.sin(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    df_featured_hourly['cos_hour'] = np.cos(2 * np.pi * df_featured_hourly['hour'] / 24)\n",
        "    \n",
        "    # Lags horários\n",
        "    for lag in [1, 24, 168]:  # 1h, 1 dia, 1 semana\n",
        "        df_featured_hourly[f'S_lag_{lag}'] = df_featured_hourly.groupby('id')['S'].shift(lag)\n",
        "    \n",
        "    # Médias móveis horárias\n",
        "    df_featured_hourly['S_rolling_mean_24'] = df_featured_hourly.groupby('id')['S'].transform(\n",
        "        lambda x: x.rolling(24, min_periods=1).mean())\n",
        "        \n",
        "        \n",
        "    return df_featured_hourly\n",
        "\n",
        "print(\"\\nCriando features de engenharia de tempo para dados horários...\")\n",
        "hourly_features = criar_features_hourly(df_hourly)\n",
        "\n",
        "# data_com_features.dropna(inplace=True)\n",
        "print(\"✅ Features horárias criadas com sucesso.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
