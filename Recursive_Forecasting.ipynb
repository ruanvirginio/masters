{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astral.sun import sun\n",
    "from astral import LocationInfo\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from skforecast.plot import plot_residuals\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.offline as poff\n",
    "pio.templates.default = \"seaborn\"\n",
    "poff.init_notebook_mode(connected=True)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "# Modelling and Forecasting\n",
    "# ==============================================================================\n",
    "import skforecast\n",
    "import lightgbm\n",
    "import sklearn\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from skforecast.recursive import ForecasterEquivalentDate, ForecasterRecursive\n",
    "from skforecast.direct import ForecasterDirect\n",
    "from skforecast.model_selection import TimeSeriesFold, bayesian_search_forecaster, backtesting_forecaster\n",
    "from skforecast.feature_selection import select_features\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.plot import calculate_lag_autocorrelation, plot_residuals\n",
    "from skforecast.metrics import calculate_coverage\n",
    "import shap\n",
    "\n",
    "url_daily = \"https://media.githubusercontent.com/media/ruanvirginio/masters/refs/heads/main/bases_tratadas/daily_peak_transformers_dataset.csv\"\n",
    "df_daily = pd.read_csv(url_daily,  sep=';', encoding='latin-1')\n",
    "\n",
    "df = df_daily\n",
    "\n",
    "data = df.copy()\n",
    "data = data.loc[data.id == 'T35']\n",
    "data['Time'] = pd.to_datetime(data['datahora'], format='%Y-%m-%d')\n",
    "data = data.set_index('Time')\n",
    "data = data.sort_index()\n",
    "data#.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define expected frequency (daily, based on your dates)\n",
    "freq = \"D\"\n",
    "\n",
    "full_index = pd.date_range(\n",
    "    start=data.index.min(),\n",
    "    end=data.index.max(),\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "data_full = data.reindex(full_index)\n",
    "\n",
    "data_interpolated = data_full.interpolate(method=\"time\")\n",
    "\n",
    "data_interpolated = (\n",
    "    data_interpolated\n",
    "    .interpolate(method=\"time\")\n",
    "    .ffill()\n",
    "    .bfill()\n",
    ")\n",
    "\n",
    "data = data_interpolated\n",
    "\n",
    "data['datahora'] = pd.to_datetime(data['datahora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c1e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['datahora'].dt.date > pd.to_datetime('2021-12-31').date()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cee9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação se possui os 2557 rows ou tem index faltando\n",
    "\n",
    "start_date = data.index.min()\n",
    "end_date = data.index.max()\n",
    "complete_date_range = pd.date_range(start=start_date, end=end_date, freq=data.index.freq)\n",
    "is_index_complete = (data.index == complete_date_range).all()\n",
    "print(f\"Index complete: {is_index_complete}\")\n",
    "print(f\"Number of rows with missing values: {data.isnull().any(axis=1).mean()}\")\n",
    "\n",
    "\n",
    "missing = completeT_date_range.difference(data.index)\n",
    "print(f\"Missing timestamps: {(missing)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b60ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-val-test\n",
    "end_train = '2022-12-31 23:59:00'\n",
    "end_validation = '2023-12-31 23:59:00'\n",
    "data_train = data.loc[: end_train, :].copy()\n",
    "data_val   = data.loc[end_train:end_validation, :].copy()\n",
    "data_test  = data.loc[end_validation:, :].copy()\n",
    "\n",
    "print(f\"Train dates      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Validation dates : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\n",
    "print(f\"Test dates       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot of time series\n",
    "# ==============================================================================\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data_train.index, y=data_train['Smax'], mode='lines', name='Train'))\n",
    "fig.add_trace(go.Scatter(x=data_val.index, y=data_val['Smax'], mode='lines', name='Validation'))\n",
    "fig.add_trace(go.Scatter(x=data_test.index, y=data_test['Smax'], mode='lines', name='Test'))\n",
    "fig.update_layout(\n",
    "    title='Daily energy demand',\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Smax\",\n",
    "    legend_title=\"Partition:\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(l=20, r=20, t=35, b=20),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1, xanchor=\"left\", x=0.001)\n",
    ")\n",
    "#fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual, weekly and daily seasonality\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 5), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Demand distribution by month\n",
    "data['month'] = data.index.month\n",
    "data.boxplot(column='Smax', by='month', ax=axs[0], flierprops={'markersize': 3, 'alpha': 0.3})\n",
    "data.groupby('month')['Smax'].median().plot(style='o-', linewidth=0.8, ax=axs[0])\n",
    "axs[0].set_ylabel('Smax')\n",
    "axs[0].set_title('Demand distribution by month', fontsize=9)\n",
    "\n",
    "# Demand distribution by week day\n",
    "data['week_day'] = data.index.day_of_week + 1\n",
    "data.boxplot(column='Smax', by='week_day', ax=axs[1], flierprops={'markersize': 3, 'alpha': 0.3})\n",
    "data.groupby('week_day')['Smax'].median().plot(style='o-', linewidth=0.8, ax=axs[1])\n",
    "axs[1].set_ylabel('Smax')\n",
    "axs[1].set_title('Demand distribution by week day', fontsize=9)\n",
    "\n",
    "fig.suptitle(\"Seasonality plots\", fontsize=12)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b647fc",
   "metadata": {},
   "source": [
    "##### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d89ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline: value of the same hour of the previous day\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterEquivalentDate(\n",
    "                 offset    = pd.DateOffset(days=365),\n",
    "                 n_offsets = 1\n",
    "             )\n",
    "\n",
    "# Train forecaster\n",
    "# ==============================================================================\n",
    "forecaster.fit(y=data.loc[:end_validation, 'Smax'])\n",
    "forecaster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc29be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting\n",
    "# ==============================================================================\n",
    "cv = TimeSeriesFold(\n",
    "        steps              = 365,\n",
    "        initial_train_size = len(data.loc[:end_validation]),\n",
    "        refit              = False\n",
    ")\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster = forecaster,\n",
    "                          y          = data['Smax'],\n",
    "                          cv         = cv,\n",
    "                          metric     = 'mean_absolute_error'\n",
    "                       )\n",
    "metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55fa25",
   "metadata": {},
   "source": [
    "#### Recursive multi-step forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster using LGBM\n",
    "# ==============================================================================\n",
    "window_features = RollingFeatures(stats=[\"mean\"], window_sizes=365 * 1) # predict proximos 365 dias, movbing average dos últimos 1 anos\n",
    "forecaster = ForecasterRecursive(\n",
    "                 estimator       = LGBMRegressor(random_state=100, verbose=-1),\n",
    "                 lags            = 365,\n",
    "                 window_features = window_features\n",
    "             )\n",
    "\n",
    "# Train forecaster\n",
    "# ==============================================================================\n",
    "forecaster.fit(y=data.loc[:end_validation, 'Smax'])\n",
    "forecaster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from skforecast.preprocessing import RollingFeatures\n",
    "# from skforecast.recursive import ForecasterRecursive\n",
    "\n",
    "# window_features = RollingFeatures(\n",
    "#     stats=[\"mean\"],\n",
    "#     window_sizes=365\n",
    "# )\n",
    "\n",
    "# forecaster = ForecasterRecursive(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=100,\n",
    "#         verbosity=0,          # <- correto\n",
    "#         n_estimators=300,\n",
    "#         max_depth=6,\n",
    "#         learning_rate=0.05\n",
    "#     ),\n",
    "#     lags=365,\n",
    "#     window_features=window_features\n",
    "# )\n",
    "\n",
    "# forecaster.fit(y=data.loc[:end_validation, 'Smax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting\n",
    "# ==============================================================================\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster    = forecaster,\n",
    "                          y             = data['Smax'],\n",
    "                          cv            = cv,\n",
    "                          metric        = 'mean_absolute_error',\n",
    "                          verbose       = True, # Set to False to avoid printing\n",
    "                      )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs real value (LGBM REGRESSOR)\n",
    "# ======================================================================================\n",
    "fig = go.Figure()\n",
    "trace1 = go.Scatter(x=data_test.index, y=data_test['Smax'], name=\"test\", mode=\"lines\")\n",
    "trace2 = go.Scatter(x=predictions.index, y=predictions['pred'], name=\"prediction\", mode=\"lines\")\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2)\n",
    "fig.update_layout(\n",
    "    title=\"Real value vs predicted in test data\",\n",
    "    xaxis_title=\"Date time\",\n",
    "    yaxis_title=\"Demand\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(l=20, r=20, t=35, b=20),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.01, xanchor=\"left\", x=0)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d5743",
   "metadata": {},
   "source": [
    "The autoregressive model achieves a lower MAE than the baseline model. This means that the autoregressive model is able to predict the next day's electricity demand more accurately than the baseline model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb095",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aeff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_GD = \"https://media.githubusercontent.com/media/ruanvirginio/scriptsMestrado/refs/heads/main/EntrantesGD.csv?token=AL5E5H3AX5L7Z7KTD3BB243JOI75Q\"\n",
    "gd = pd.read_csv(url_GD,  sep=';', encoding='latin-1')\n",
    "\n",
    "url_clientes = \"https://media.githubusercontent.com/media/ruanvirginio/scriptsMestrado/refs/heads/main/Base_Quantidade_Clientes.csv?token=AL5E5H3BXZZT6EZOGNVLC7DJOI75S\"\n",
    "clientes = pd.read_csv(url_clientes, sep=';', encoding='latin-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
